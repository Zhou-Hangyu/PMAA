{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d5c461e-48cf-496e-9549-bd0ab461368a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys, os, torch\n",
    "if \"ck696\" in os.getcwd():\n",
    "    sys.path.append(\"/share/hariharan/ck696/allclear\")\n",
    "else:\n",
    "    sys.path.append(\"/share/hariharan/cloud_removal/allclear\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0bcf3a1-f415-493c-867d-a8536f126dd1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ck696/.conda/envs/H3/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: /home/ck696/.conda/envs/H3/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c106detail19maybe_wrap_dim_slowEllb\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(root='/share/hariharan/cloud_removal', root_file='/share/hariharan/ck696/allclear/baselines/PMAA/data', cloud_model_path='./data/Feature_Extrator_FS2.pth', save_model_path='./checkpoints0515', dataset_name='CTGAN_Sen2_MTC', load_gen='', load_dis='', n_epochs=100, gan_mode='lsgan', optimizer='AdamW', lr=0.0005, workers=1, batch_size=1, lambda_L1=100.0, lambda_aux=50.0, in_channel=4, out_channel=4, image_size=256, aux_loss=False, label_noise=False, gpu_id='0', manual_seed=2022)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mck696\u001b[0m (\u001b[33mcornell-kao\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/share/hariharan/ck696/allclear/baselines/PMAA/wandb/run-20240522_082204-ntsz5n19</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/cornell-kao/allclear-pmaa-v1/runs/ntsz5n19' target=\"_blank\">PMAA_SEN2MTC_lm100_la50_bs1_seed2022</a></strong> to <a href='https://wandb.ai/cornell-kao/allclear-pmaa-v1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/cornell-kao/allclear-pmaa-v1' target=\"_blank\">https://wandb.ai/cornell-kao/allclear-pmaa-v1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/cornell-kao/allclear-pmaa-v1/runs/ntsz5n19' target=\"_blank\">https://wandb.ai/cornell-kao/allclear-pmaa-v1/runs/ntsz5n19</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load cloud_detection_model\n",
      "Load ours model\n",
      "Start training!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train[0/100]:   0% 0/2380 [00:00<?, ? step/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "learning rate = 0.0005000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train[0/100]:   0% 10/2380 [00:06<16:58,  2.33 step/s, D_fake=1.0367, D_real=1.4157, G_GAN=1.3759, G_L1=36.6609, G_L1_total=640.3548] "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 370\u001b[0m\n\u001b[1;32m    366\u001b[0m     wandb\u001b[38;5;241m.\u001b[39mlog({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_ssim\u001b[39m\u001b[38;5;124m\"\u001b[39m: ssim}, step\u001b[38;5;241m=\u001b[39mepoch)\n\u001b[1;32m    368\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m psnr, ssim\n\u001b[0;32m--> 370\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mGEN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mDIS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcloud_detection_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer_G\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    371\u001b[0m \u001b[43m      \u001b[49m\u001b[43moptimizer_D\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[2], line 273\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(opt, model_GEN, model_DIS, cloud_detection_model, optimizer_G, optimizer_D, train_loader, val_loader)\u001b[0m\n\u001b[1;32m    270\u001b[0m loss_G\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m    271\u001b[0m optimizer_G\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m--> 273\u001b[0m \u001b[43mwriter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_scalar\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtraining_G_GAN\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_G_GAN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_update\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    274\u001b[0m writer\u001b[38;5;241m.\u001b[39madd_scalar(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtraining_G_L1\u001b[39m\u001b[38;5;124m'\u001b[39m, loss_G_L1, train_update)\n\u001b[1;32m    275\u001b[0m writer\u001b[38;5;241m.\u001b[39madd_scalar(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtraining_D_real\u001b[39m\u001b[38;5;124m'\u001b[39m, loss_D_real, train_update)\n",
      "File \u001b[0;32m~/.conda/envs/H3/lib/python3.10/site-packages/tensorboardX/writer.py:456\u001b[0m, in \u001b[0;36mSummaryWriter.add_scalar\u001b[0;34m(self, tag, scalar_value, global_step, walltime, display_name, summary_description)\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    454\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInput value: \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m is not a scalar\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(scalar_value))\n\u001b[1;32m    455\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_file_writer()\u001b[38;5;241m.\u001b[39madd_summary(\n\u001b[0;32m--> 456\u001b[0m     \u001b[43mscalar\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtag\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscalar_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdisplay_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msummary_description\u001b[49m\u001b[43m)\u001b[49m, global_step, walltime)\n\u001b[1;32m    457\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_comet_logger()\u001b[38;5;241m.\u001b[39mlog_metric(tag, display_name, scalar_value, global_step)\n",
      "File \u001b[0;32m~/.conda/envs/H3/lib/python3.10/site-packages/tensorboardX/summary.py:152\u001b[0m, in \u001b[0;36mscalar\u001b[0;34m(name, scalar, display_name, summary_description)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Outputs a `Summary` protocol buffer containing a single scalar value.\u001b[39;00m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;124;03mThe generated Summary has a Tensor.proto containing the input Tensor.\u001b[39;00m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;124;03m  ValueError: If tensor has the wrong shape or type.\u001b[39;00m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    151\u001b[0m name \u001b[38;5;241m=\u001b[39m _clean_tag(name)\n\u001b[0;32m--> 152\u001b[0m scalar \u001b[38;5;241m=\u001b[39m \u001b[43mmake_np\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscalar\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m scalar\u001b[38;5;241m.\u001b[39msqueeze()\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscalar should be 0D\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    154\u001b[0m scalar \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(scalar\u001b[38;5;241m.\u001b[39msqueeze())\n",
      "File \u001b[0;32m~/.conda/envs/H3/lib/python3.10/site-packages/tensorboardX/x2num.py:28\u001b[0m, in \u001b[0;36mmake_np\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m check_nan(np\u001b[38;5;241m.\u001b[39marray([x]))\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtorch\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mtype\u001b[39m(x)):\n\u001b[0;32m---> 28\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m check_nan(\u001b[43mprepare_pytorch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchainer\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mtype\u001b[39m(x)):\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m check_nan(prepare_chainer(x))\n",
      "File \u001b[0;32m~/.conda/envs/H3/lib/python3.10/site-packages/tensorboardX/x2num.py:43\u001b[0m, in \u001b[0;36mprepare_pytorch\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mVariable):\n\u001b[1;32m     42\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mdata\n\u001b[0;32m---> 43\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"WANDB_API_KEY\"] = \"5f04d2ce100707f23b71379f67f28901d496edda\"\n",
    "# os.environ[\"WANDB_MODE\"] = \"disabled\"\n",
    "\n",
    "import warnings\n",
    "from utils import set_requires_grad, get_rgb, GANLoss\n",
    "from utils import *\n",
    "from tensorboardX import SummaryWriter\n",
    "import tqdm\n",
    "import torch\n",
    "import argparse\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from dataset_new import Sen2_MTC\n",
    "from model.fe import FeatureExtractor\n",
    "from model.pmaa import PMAA\n",
    "from model.discriminator import Discriminator\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "import numpy as np\n",
    "import wandb\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "cuda = True if torch.cuda.is_available() else False\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "\"\"\"Path\"\"\"\n",
    "# parser.add_argument(\"--root\", type=str, default='/share/hariharan/ck696',\n",
    "parser.add_argument(\"--root\", type=str, default= '/share/hariharan/cloud_removal', \n",
    "                    choices=['/scratch/allclear', '/share/hariharan/ck696'],\n",
    "                    help=\"Path to dataset\")\n",
    "parser.add_argument(\"--root_file\", type=str, default='/share/hariharan/ck696/allclear/baselines/PMAA/data', \n",
    "                    help=\"Path to dataset\")\n",
    "parser.add_argument(\"--cloud_model_path\", type=str,\n",
    "                    default='./data/Feature_Extrator_FS2.pth', help=\"path to feature extractor model\")\n",
    "parser.add_argument(\"--save_model_path\", type=str,\n",
    "                    default='./checkpoints0515', help=\"Path to save model\")\n",
    "parser.add_argument(\"--dataset_name\", type=str, choices=[\"CTGAN_Sen2_MTC\", \"AllClear\"],\n",
    "                    default='CTGAN_Sen2_MTC', help=\"name of the dataset\")\n",
    "parser.add_argument(\"--load_gen\", type=str, default='',\n",
    "                    help=\"path to the model of generator\")\n",
    "parser.add_argument(\"--load_dis\", type=str, default='',\n",
    "                    help=\"path to the model of discriminator\")\n",
    "\n",
    "\"\"\"Parameters\"\"\"\n",
    "parser.add_argument(\"--n_epochs\", type=int,\n",
    "                    default=100, help=\"Number of epochs\")\n",
    "parser.add_argument(\"--gan_mode\", type=str, default='lsgan',\n",
    "                    help=\"Which gan mode(lsgan/vanilla)\")\n",
    "parser.add_argument(\"--optimizer\", type=str, default='AdamW',\n",
    "                    help=\"optimizer you want to use(AdamW/SGD)\")\n",
    "parser.add_argument(\"--lr\", type=float, default=5e-4, help=\"learning rate\")\n",
    "parser.add_argument(\"--workers\", type=int, default=1,\n",
    "                    help=\"number of cpu threads to use during batch generation\")\n",
    "parser.add_argument(\"--batch_size\", type=int,\n",
    "                    default=1, help=\"size of the batches\")\n",
    "parser.add_argument('--lambda_L1', type=float,\n",
    "                    default=100.0, help='weight for L1 loss')\n",
    "parser.add_argument('--lambda_aux', type=float,\n",
    "                    default=50.0, help='weight for aux loss')\n",
    "parser.add_argument(\"--in_channel\", type=int, default=4,\n",
    "                    help=\"the number of input channels\")\n",
    "parser.add_argument(\"--out_channel\", type=int, default=4,\n",
    "                    help=\"the number of output channels\")\n",
    "parser.add_argument(\"--image_size\", type=int,\n",
    "                    default=256, help=\"crop size\")\n",
    "parser.add_argument(\"--aux_loss\", action='store_true',\n",
    "                    help=\"whether use auxiliary loss(1/0)\")\n",
    "parser.add_argument(\"--label_noise\", action='store_true',\n",
    "                    help=\"whether to add noise on the label of gan training\")\n",
    "\n",
    "\"\"\"base_options\"\"\"\n",
    "parser.add_argument(\"--gpu_id\", type=str, default='0', help=\"gpu id\")\n",
    "parser.add_argument(\"--manual_seed\", type=int,\n",
    "                    default=2022, help=\"random_seed you want\")\n",
    "\n",
    "opt, _ = parser.parse_known_args()\n",
    "print(opt)\n",
    "\n",
    "if opt.dataset_name == \"CTGAN_Sen2_MTC\": dataset_name_ = \"SEN2MTC\"\n",
    "if opt.dataset_name == \"AllClear\": dataset_name_ = \"AllClear\"\n",
    "run_name = f\"PMAA_{dataset_name_}_lm{int(opt.lambda_L1)}_la{int(opt.lambda_aux)}_bs{opt.batch_size}_seed{opt.manual_seed}\"\n",
    "wandb.init(project=\"allclear-pmaa-v1\", name=run_name, config=opt)\n",
    "\n",
    "os.makedirs(os.path.join(opt.save_model_path,\n",
    "            run_name), exist_ok=True)\n",
    "fixed_seed(opt.manual_seed)\n",
    "\n",
    "if opt.dataset_name == \"AllClear\":\n",
    "\n",
    "    from dataset.dataloader_v1 import CRDataset\n",
    "    from torch.utils.data import DataLoader\n",
    "\n",
    "    import json\n",
    "    with open('/scratch/allclear/metadata/v3/test_tx3_v1.json') as f:\n",
    "        metadata = json.load(f)\n",
    "    #len=3168\n",
    "    train_data = CRDataset(metadata, \n",
    "                        selected_rois=\"all\", \n",
    "                        main_sensor=\"s2_toa\", \n",
    "                        aux_sensors=[],\n",
    "                        aux_data=[],\n",
    "                        format=\"stp\",\n",
    "                        target=\"s2p\",\n",
    "                        tx=3)\n",
    "    train_loader = DataLoader(train_data, batch_size=opt.batch_size, shuffle=True,\n",
    "                              num_workers=opt.workers, drop_last=True, pin_memory=True, persistent_workers=True)\n",
    "    \n",
    "elif opt.dataset_name == \"CTGAN_Sen2_MTC\":\n",
    "    # len=1190\n",
    "    train_data = Sen2_MTC(opt, 'train')\n",
    "    train_loader = DataLoader(train_data, batch_size=opt.batch_size, shuffle=True,\n",
    "                              num_workers=opt.workers, drop_last=True, pin_memory=True, persistent_workers=True)\n",
    "\n",
    "val_data = Sen2_MTC(opt, mode='val')\n",
    "val_loader = DataLoader(val_data, batch_size=opt.batch_size, shuffle=False,\n",
    "                        num_workers=opt.workers, drop_last=False, pin_memory=True, persistent_workers=True)\n",
    "\n",
    "# assert 0 == 1\n",
    "print('Load cloud_detection_model')\n",
    "cloud_detection_model = FeatureExtractor()\n",
    "cloud_detection_model.load_state_dict(torch.load(opt.cloud_model_path))\n",
    "cloud_detection_model.eval()\n",
    "set_requires_grad(cloud_detection_model, False)\n",
    "\n",
    "print('Load ours model')\n",
    "GEN = PMAA(32, 4)\n",
    "\n",
    "def replace_batchnorm(model):\n",
    "    for name, child in model.named_children():\n",
    "        if isinstance(child, torch.nn.BatchNorm2d):\n",
    "            child: torch.nn.BatchNorm2d = child\n",
    "            setattr(model, name, torch.nn.InstanceNorm2d(child.num_features))\n",
    "        else:\n",
    "            replace_batchnorm(child)\n",
    "replace_batchnorm(GEN)\n",
    "DIS = Discriminator()\n",
    "\n",
    "if opt.load_gen and opt.load_dis:\n",
    "    print('loading pre-trained model')\n",
    "    GEN.load_state_dict(torch.load(opt.load_gen))\n",
    "    DIS.load_state_dict(torch.load(opt.load_dis))\n",
    "\n",
    "if opt.optimizer == 'AdamW':\n",
    "    optimizer_G = torch.optim.AdamW(\n",
    "        GEN.parameters(), lr=opt.lr, betas=(0.5, 0.999), weight_decay=5e-4)\n",
    "    optimizer_D = torch.optim.AdamW(\n",
    "        DIS.parameters(), lr=opt.lr, betas=(0.5, 0.999), weight_decay=5e-4)\n",
    "if opt.optimizer == 'SGD':\n",
    "    optimizer_G = torch.optim.SGD(\n",
    "        GEN.parameters(), lr=opt.lr, momentum=0.9, nesterov=True)\n",
    "    optimizer_D = torch.optim.SGD(\n",
    "        DIS.parameters(), lr=opt.lr, momentum=0.9, nesterov=True)\n",
    "\n",
    "# def train(opt, model_GEN, model_DIS, cloud_detection_model, optimizer_G, optimizer_D, train_loader, val_loader):\n",
    "\n",
    "model_GEN = GEN\n",
    "model_DIS = DIS\n",
    "\n",
    "def preprocess_images(opt, batch, pmaa_bands=(3,2,1,7)):\n",
    "    if opt.dataset_name == \"CTGAN_Sen2_MTC\":\n",
    "        real_A, real_B, _ = batch\n",
    "        return real_A[0].cuda(), real_A[1].cuda(), real_A[2].cuda(), real_B.cuda()\n",
    "    elif opt.dataset_name == \"AllClear\":        \n",
    "        real_As = batch[\"input_images\"] * 2 - 1\n",
    "        real_Bs = batch[\"target\"] * 2 - 1\n",
    "        return real_As[:,pmaa_bands,0].cuda(), real_As[:,pmaa_bands,1].cuda(), real_As[:,pmaa_bands,2].cuda(), real_Bs[:,pmaa_bands,0].cuda()\n",
    "\n",
    "def train(opt, model_GEN, model_DIS, cloud_detection_model, optimizer_G, optimizer_D, train_loader, val_loader):\n",
    "    writer = SummaryWriter('runs29/%s' % opt.dataset_name)\n",
    "\n",
    "    noise = opt.label_noise\n",
    "    criterionGAN = GANLoss(opt.gan_mode)\n",
    "    criterionL1 = torch.nn.L1Loss()\n",
    "    criterionMSE = nn.MSELoss()\n",
    "\n",
    "    if cuda:\n",
    "        criterionGAN = criterionGAN.cuda()\n",
    "        criterionL1 = criterionL1.cuda()\n",
    "        criterionMSE = criterionMSE.cuda()\n",
    "        cloud_detection_model = cloud_detection_model.cuda()\n",
    "        model_GEN = model_GEN.cuda()\n",
    "        model_DIS = model_DIS.cuda()\n",
    "\n",
    "    \"\"\"lr_scheduler\"\"\"\n",
    "    scheduler_G = CosineAnnealingLR(\n",
    "        optimizer_G, T_max=opt.n_epochs, eta_min=1e-6)\n",
    "    scheduler_D = CosineAnnealingLR(\n",
    "        optimizer_D, T_max=opt.n_epochs, eta_min=1e-6)\n",
    "\n",
    "    \"\"\"training\"\"\"\n",
    "    train_update = 0\n",
    "    psnr_max = 0.\n",
    "    ssim_max = 0.\n",
    "\n",
    "    print('Start training!')\n",
    "    for epoch in range(opt.n_epochs):\n",
    "        model_GEN.train()\n",
    "        model_DIS.train()\n",
    "\n",
    "        pbar = tqdm.tqdm(total=len(train_loader), ncols=0,\n",
    "                         desc=\"Train[%d/%d]\" % (epoch, opt.n_epochs), unit=\" step\")\n",
    "\n",
    "        lr = optimizer_G.param_groups[0]['lr']\n",
    "        print('\\nlearning rate = %.7f' % lr)\n",
    "\n",
    "        L1_total = 0\n",
    "        for batch_ids, batch in enumerate(train_loader): \n",
    "            \n",
    "            if (batch_ids+1) >= 2380 // opt.batch_size: break\n",
    "                \n",
    "            if (batch_ids+1) >= 100 // opt.batch_size: break\n",
    "            \n",
    "            real_A = [[], [], []]\n",
    "            real_A[0], real_A[1], real_A[2], real_B = preprocess_images(opt, batch)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                M0, _, _ = cloud_detection_model(real_A[0])\n",
    "                M1, _, _ = cloud_detection_model(real_A[1])\n",
    "                M2, _, _ = cloud_detection_model(real_A[2])\n",
    "            M = [M0, M1, M2]\n",
    "\n",
    "            real_A_combined = torch.cat(\n",
    "                (real_A[0], real_A[1], real_A[2]), 1).cuda()\n",
    "            real_A_input = torch.stack(\n",
    "                (real_A[0], real_A[1], real_A[2]), 1).cuda()\n",
    "\n",
    "            \"\"\"forward generator\"\"\"\n",
    "            fake_B, cloud_mask, aux_pred = model_GEN(real_A_input)\n",
    "\n",
    "            \"\"\"update Discriminator\"\"\"\n",
    "            set_requires_grad(model_DIS, True)\n",
    "            optimizer_D.zero_grad()\n",
    "\n",
    "            fake_AB = torch.cat((real_A_combined, fake_B), 1)\n",
    "            pred_fake = model_DIS(fake_AB.detach())\n",
    "            loss_D_fake = criterionGAN(pred_fake, False, noise)\n",
    "\n",
    "            real_AB = torch.cat((real_A_combined, real_B), 1)\n",
    "            pred_real = model_DIS(real_AB)\n",
    "            loss_D_real = criterionGAN(pred_real, True, noise)\n",
    "\n",
    "            loss_D = (loss_D_fake + loss_D_real) * 0.5\n",
    "            loss_D.backward()\n",
    "            optimizer_D.step()\n",
    "\n",
    "            \"\"\"update generator\"\"\"\n",
    "            optimizer_G.zero_grad()\n",
    "            set_requires_grad(model_DIS, False)\n",
    "\n",
    "            fake_AB = torch.cat((real_A_combined, fake_B), 1)\n",
    "            pred_fake = model_DIS(fake_AB)\n",
    "            loss_G_GAN = criterionGAN(pred_fake, True, noise)\n",
    "\n",
    "            loss_G_L1 = criterionL1(fake_B, real_B) * opt.lambda_L1\n",
    "            L1_total += loss_G_L1.item()\n",
    "\n",
    "            loss_g_att = 0\n",
    "            for i in range(len(cloud_mask)):\n",
    "                loss_g_att += criterionMSE(cloud_mask[i]\n",
    "                                           [:, 0, :, :], M[i][:, 0, :, :])\n",
    "\n",
    "            if opt.aux_loss:\n",
    "                loss_G_aux = (criterionL1(aux_pred[0], real_B) + criterionL1(\n",
    "                    aux_pred[1], real_B) + criterionL1(aux_pred[2], real_B)) * opt.lambda_aux\n",
    "                loss_G = loss_G_GAN + loss_G_L1 + loss_g_att + loss_G_aux\n",
    "            else:\n",
    "                loss_G = loss_G_GAN + loss_G_L1 + loss_g_att\n",
    "            loss_G.backward()\n",
    "            optimizer_G.step()\n",
    "\n",
    "            writer.add_scalar('training_G_GAN', loss_G_GAN, train_update)\n",
    "            writer.add_scalar('training_G_L1', loss_G_L1, train_update)\n",
    "            writer.add_scalar('training_D_real', loss_D_real, train_update)\n",
    "            writer.add_scalar('training_D_fake', loss_D_fake, train_update)\n",
    "            writer.add_scalar('training_D_fake', loss_g_att, train_update)\n",
    "            \n",
    "            \n",
    "            wandb.log({\n",
    "                'training_G_GAN': loss_G_GAN,\n",
    "                'training_G_L1': loss_G_L1,\n",
    "                'training_D_real': loss_D_real,\n",
    "                'training_D_fake': loss_D_fake,\n",
    "                'training_g_att': loss_g_att\n",
    "            }, step=train_update)\n",
    "            \n",
    "\n",
    "            pbar.update()\n",
    "            pbar.set_postfix(\n",
    "                G_GAN=f\"{loss_G_GAN:.4f}\",\n",
    "                G_L1=f\"{loss_G_L1:.4f}\",\n",
    "                G_L1_total=f\"{L1_total:.4f}\",\n",
    "                D_real=f\"{loss_D_real:.4f}\",\n",
    "                D_fake=f\"{loss_D_fake:.4f}\"\n",
    "            )\n",
    "            train_update += 1\n",
    "            \n",
    "        pbar.close()\n",
    "        \"\"\"validation\"\"\"\n",
    "        psnr, ssim = valid(opt, model_GEN, val_loader,\n",
    "                           criterionL1, writer, epoch)\n",
    "\n",
    "        if psnr_max < psnr:\n",
    "            psnr_max = psnr\n",
    "            torch.save(model_GEN.state_dict(), os.path.join(\n",
    "                opt.save_model_path, run_name, f'EP{epoch}_G_best_PSNR_{psnr:.3f}_SSIM_{ssim:.3f}.pth'))\n",
    "\n",
    "        if ssim_max < ssim:\n",
    "            ssim_max = ssim\n",
    "            torch.save(model_GEN.state_dict(), os.path.join(\n",
    "                opt.save_model_path, run_name, f'EP{epoch}_G_best_SSIM_{ssim:.3f}_PNSR_{psnr:.3f}.pth'))\n",
    "\n",
    "        scheduler_D.step()\n",
    "        scheduler_G.step()\n",
    "\n",
    "    print('Best PSNR: %.3f | Best SSIM: %.3f' % (psnr_max, ssim_max))\n",
    "\n",
    "def valid(opt, model_GEN, val_loader, criterionL1, writer, epoch):\n",
    "    model_GEN.eval()\n",
    "\n",
    "    psnr_list = []\n",
    "    ssim_list = []\n",
    "    total_loss = 0\n",
    "\n",
    "    pbar = tqdm.tqdm(total=len(val_loader), ncols=0,\n",
    "                     desc=\"Valid[%d/%d]\" % (epoch, opt.n_epochs), unit=\" step\")\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            \n",
    "            real_A = [[], [], []]\n",
    "            real_A[0], real_A[1], real_A[2], real_B = preprocess_images(opt, batch)\n",
    "\n",
    "            real_A_input = torch.stack(\n",
    "                (real_A[0], real_A[1], real_A[2]), 1).cuda()\n",
    "            fake_B, _, _ = model_GEN(real_A_input)\n",
    "\n",
    "            loss = criterionL1(fake_B, real_B)\n",
    "\n",
    "            for batch_idx in range(len(real_B)):\n",
    "                output, label = fake_B[batch_idx], real_B[batch_idx]\n",
    "                output_rgb, label_rgb = get_rgb(output), get_rgb(label)\n",
    "\n",
    "                psnr, ssim = psnr_ssim_cal(label_rgb, output_rgb)\n",
    "                psnr_list.append(psnr)\n",
    "                ssim_list.append(ssim)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            pbar.update()\n",
    "            pbar.set_postfix(\n",
    "                loss_val=f\"{total_loss:.4f}\"\n",
    "            )\n",
    "    psnr_list = np.array(psnr_list)\n",
    "    ssim_list = np.array(ssim_list)\n",
    "    psnr = np.mean(psnr_list)\n",
    "    ssim = np.mean(ssim_list)\n",
    "\n",
    "    writer.add_scalar('validation_PSNR', psnr, epoch)\n",
    "    writer.add_scalar('validation_SSIM', ssim, epoch)\n",
    "    pbar.set_postfix(loss_val=f\"{total_loss:.4f}\",\n",
    "                     psnr=f\"{psnr:.3f}\", ssim=f\"{ssim:.3f}\")\n",
    "\n",
    "    pbar.close()\n",
    "    \n",
    "    wandb.log({\"val_psnr\": psnr}, step=epoch)\n",
    "    wandb.log({\"val_ssim\": ssim}, step=epoch)\n",
    "    \n",
    "    return psnr, ssim\n",
    "\n",
    "train(opt, GEN, DIS, cloud_detection_model, optimizer_G,\n",
    "      optimizer_D, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7791cfdb-5524-4851-9924-236215a75670",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "H3",
   "language": "python",
   "name": "h3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
